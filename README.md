# ğŸ”¥ Language Interpretability Tool (LIT)

è¯­è¨€å¯è§£é‡Šæ€§å·¥å…·ï¼ˆLITï¼‰æ˜¯ä¸€ç§å¯è§†çš„ï¼Œäº¤äº’å¼çš„
ç”¨äºNLPæ¨¡å‹çš„æ¨¡å‹ç†è§£å·¥å…·ã€‚

LITæ—¨åœ¨å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
* **å“ªç§ç¤ºä¾‹**åœ¨æˆ‘çš„æ¨¡å‹ä¸Šæ•ˆæœä¸ä½³ï¼Ÿ
* **ä¸ºä»€ä¹ˆæˆ‘çš„æ¨¡å‹åšå‡ºæ­¤é¢„æµ‹ï¼Ÿ**è¯¥é¢„æµ‹å¯ä»¥å½’å› äºå¯¹æŠ—è¡Œä¸ºè¿˜æ˜¯è®­ç»ƒé›†ä¸­çš„ä¸è‰¯å…ˆéªŒï¼Ÿ
* **å¦‚æœæˆ‘æ›´æ”¹æ–‡æœ¬æ ·å¼ï¼ŒåŠ¨è¯æ—¶æ€æˆ–ä»£è¯æ€§åˆ«ä¹‹ç±»çš„å†…å®¹ï¼Œæˆ‘çš„æ¨¡å‹æ˜¯å¦ä¼šè¡¨ç°ä¸€è‡´**ï¼Ÿ

![Example of LIT UI](docs/images/figure-1.png)

LITé€šè¿‡åŸºäºæµè§ˆå™¨çš„UIæ”¯æŒå„ç§è°ƒè¯•å·¥ä½œæµã€‚
åŠŸèƒ½åŒ…æ‹¬ï¼š

* **Local explanations** é€šè¿‡æ˜¾ç€å›¾ï¼Œæ³¨æ„åŠ›å’Œä¸°å¯Œçš„æ¨¡å‹é¢„æµ‹å¯è§†åŒ–ã€‚
* **Aggregate analysis**ï¼ŒåŒ…æ‹¬è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œåˆ‡ç‰‡å’Œbinningä»¥åŠåµŒå…¥ç©ºé—´çš„å¯è§†åŒ–ã€‚
* **Counterfactual generation**, é€šè¿‡ç¼–è¾‘æˆ–ç”Ÿæˆå™¨æ’ä»¶æ¥çœŸå®ç”Ÿæˆï¼Œä»¥åŠ¨æ€åˆ›å»ºå’Œè¯„ä¼°æ–°ç¤ºä¾‹ã€‚
* **Side-by-side mode**, æ¯”è¾ƒä¸¤ä¸ªæˆ–å¤šä¸ªæ¨¡å‹ï¼Œæˆ–ä¸€å¯¹ç¤ºä¾‹ä¸­çš„ä¸€ä¸ªæ¨¡å‹ã€‚
* **Highly extensible**åˆ°æ–°æ¨¡å‹ç±»å‹ï¼ŒåŒ…æ‹¬åˆ†ç±»ï¼Œå›å½’ï¼Œè·¨åº¦æ ‡ç­¾ï¼Œseq2seqå’Œè¯­è¨€å»ºæ¨¡ã€‚ å¼€ç®±å³ç”¨åœ°æ”¯æŒmulti-head æ¨¡å‹å’Œå¤šç§è¾“å…¥ç‰¹å¾ã€‚
* **ä¸æ¡†æ¶æ— å…³**ï¼Œä¸TensorFlowï¼ŒPyTorchç­‰å…¼å®¹ã€‚

æœ‰å…³æ›´å¹¿æ³›çš„æ¦‚è¿°ï¼Œè¯·æŸ¥çœ‹[our paper](https://arxiv.org/abs/2008.05122) å’Œ[user guide](docs/user_guide.md)ã€‚

## Documentation
*   [User Guide](docs/user_guide.md)
*   [Developer Guide](docs/development.md)
*   [FAQ](docs/faq.md)

## Download and Installation

ä¸‹è½½repoå¹¶è®¾ç½®Pythonç¯å¢ƒï¼š

```sh
git clone https://github.com/PAIR-code/lit.git ~/lit

# Set up Python environment
cd ~/lit
conda env create -f environment.yml
conda activate lit-nlp
conda install cudnn cupti  # optional, for GPU support
conda install -c pytorch pytorch  # optional, for PyTorch

# Build the frontend
cd ~/lit/lit_nlp/client
yarn && yarn build
```

## Running LIT

### Quick-start: sentiment classifier

```sh
cd ~/lit
python -m lit_nlp.examples.quickstart_sst_demo --port=5432
```

è¿™å°†åœ¨[Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/treebank.html)ä¸Šå¾®è°ƒ[BERT-tiny](https://arxiv.org/abs/1908.08962)æ¨¡å‹ï¼Œ 
åœ¨GPUä¸Šçš„æ—¶é—´åº”è¯¥å°‘äº5åˆ†é’Ÿã€‚ è®­ç»ƒå®Œæˆåï¼Œåœ¨å¼€å‘é›†ä¸Šå¯åŠ¨LITæœåŠ¡ï¼› http://localhost:5432ä½œä¸ºç”¨æˆ·ç•Œé¢ã€‚


### Quick start: language modeling

è¦æ¢ç´¢é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼ˆBERTæˆ–GPT-2ï¼‰çš„é¢„æµ‹ï¼Œè¯·è¿è¡Œï¼š

```sh
cd ~/lit
python -m lit_nlp.examples.pretrained_lm_demo --models=bert-base-uncased \
  --port=5432
```

And navigate to http://localhost:5432 for the UI.

### More Examples

See ../lit_nlp/examples. Run similarly to the above:

```sh
cd ~/lit
python -m lit_nlp.examples.<example_name> --port=5432 [optional --args]
```

## User Guide

è¦äº†è§£LITçš„åŠŸèƒ½ï¼Œ check out the [user guide](docs/user_guide.md), or
watch this [short video](https://www.youtube.com/watch?v=j0OfBWFUqIE).

## æ·»åŠ è‡ªå·±çš„æ¨¡å‹æˆ–æ•°æ®

æ‚¨å¯ä»¥é€šè¿‡åˆ›å»ºè‡ªå®šä¹‰`demo.py`å¯åŠ¨å™¨æ¥è½»æ¾åœ°ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹è¿è¡ŒLITï¼Œ
ç±»ä¼¼äº../lit_nlp/examplesã€‚ åŸºç¡€çš„æ­¥éª¤æ˜¯ï¼š

*   Write a data loader which follows the
    [`Dataset` API](docs/python_api.md#datasets)
*   Write a model wrapper which follows the [`Model` API](docs/python_api.md#models)
*   Pass models, datasets, and any additional
    [components](docs/python_api.md#interpretation-components) to the LIT server class

æœ‰å…³å®Œæ•´çš„æ¼”ç»ƒï¼Œ see
[adding models and data](docs/python_api.md#adding-models-and-data).

## ç”¨æ–°ç»„ä»¶æ‰©å±•LIT

LITæ˜“äºåœ¨å‰ç«¯æˆ–åç«¯ä½¿ç”¨æ–°çš„å¯è§£é‡Šæ€§ç»„ä»¶ï¼Œç”Ÿæˆå™¨ç­‰è¿›è¡Œæ‰©å±•ã€‚ è§
[developer guide](docs/development.md) to get started.

## Citing LIT

If you use LIT as part of your work, please cite:

```
@misc{tenney2020language,
    title={The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models},
    author={Ian Tenney and James Wexler and Jasmijn Bastings and Tolga Bolukbasi and Andy Coenen and Sebastian Gehrmann and Ellen Jiang and Mahima Pushkarna and Carey Radebaugh and Emily Reif and Ann Yuan},
    year={2020},
    eprint={2008.05122},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
```

## Disclaimer

This is not an official Google product.
